Serkan Ozdemir
manufacturability of these chips increasingly difficult [24, 39]. With process technologies scaling from 350 nanometers to 90 nanometers, chip yields have dropped from over 90% to just above 50% [18]. A recent study on 45 nanometer technologies reports yields around 30% [3]. This trend is depicted in Figure 1, which shows the expected yield for different manufacturing technologies and the factors on which the yield loss is attributed to. Factors limiting chip yields can be grouped into three categories defect-density related yield loss, lithography based yield loss, and parametric yield loss. Defect-density related problems are caused by actual errors with the silicon, such as when a contaminating particle is introduced during fabrication. These are well-controlled as silicon and clean-room technology becomes more efficient. Lithography based failures occur when there are defects on the masks used to burn the silicon. These are tied to reticle patterns and are controlled as process technologies mature. Parametric yield loss, on the other hand, occurs because the manufactured chip does not meet a design parameter. For example, a microprocessor, which does not meet a frequency constraint or consumes too much power, may be tossed away.
1. Introduction
* This work is in part supported by NSF grant CCF-0541337
* * Debjit Sinha is currently with IBM Microelectronics, USA
As shown in Figure 1, the impact of all the above factors has worsened with technology scaling. However, parametric losses are the largest inhibitor to chip yields [18] and contribute significantly to overall yield losses starting from the 0.18 micrometer technology generation [1, 10, 16, 24, 25]. For sub-180nm technologies, it becomes harder to control variations in device parameters such as channel length, gate width, oxide thickness, and device threshold voltage. Even in a mature technology like 130nm, these variations are known to cause a 30% variation in maximum allowable frequency of operation, and a fivefold increase in leakage power [10]. For newer technologies, these variations
significantly under process variations. Hence, the probability that a chip will not meet the performance power constraints because of its data cache is high. To optimize the yield, we aim to reduce losses due to both performance and power constraints. First, we develop
the Yield-Aware Power-Down YAPD technique.
Although the notion of YAPD can be applied to different power reduction techniques, in this paper we use a scheme that combines Selective Cache Ways [4] and Gated-Vdd [30] as the example of a yield-unaware power reduction technique. Specifically, we modify this yield-unaware scheme with YAPD to investigate how the yield is affected by our optimization. The main idea in YAPD is to turn off cache ways that cause delay failures. In addition, cache ways can be turned off if they consume excessively large leakage power. We modify this approach to compensate for correlations in process variation parameters. Particularly, we develop the Horizontal YAPD H-YAPD , which turns off horizontal regions of a cache, instead of a vertical cache way. This optimization reduces the probability of yield loss as we will elaborate further in Section 4.2. By making a small modification in the decoder, we guarantee that the closed regions do not share any common addresses. As a result, for any memory address, the associativity of the cache is identical. Third, we develop the VAriable-latency Cache Architecture VACA . In a VACA, different cache ways can be accessed with different latencies. The main idea is similar to NUCA [19], however, since we apply the variability to the level 1 data caches, we have to modify the architecture to perform the corresponding instruction scheduling. In addition, we augment the functional units with special buffers that allow an instruction depending on a load operation to stall for a cycle if the load operation is delayed. As a result, if some accesses take longer than the predefined number of cycles, the execution can still be performed correctly, and hence yields are improved over their current levels. Finally, we analyze a Hybrid scheme, which combines YAPD or H-YAPD and VACA. By combining the advantages of both schemes, the Hybrid scheme achieves the best yield optimizations. In the next section, we explain how process variations affect yield loss. Section 3 illustrates our cache architecture and our methodology for modeling the process variations on it. Section 4 describes our yield-aware architectures. Section 5 presents the results and Section 6 summarizes related work. We conclude the paper in Section 7 with a summary.
2. Process Variations and Their Effects on Parametric Yield Loss
Process variations can be classified into inter-die variations and intra-die variations [2, 8]. Inter-die variations denote the variations that occur from one die to the next, from wafer to wafer, and from wafer lot to another. Inter-die variations affect all devices on the same chip similarly, and was considered to be the primary source of process variations in older technology generations [8]. Intra-die
the interconnect parameters results in a change in its electrical properties, including the resistance R and capacitance C . These electrical parameter variations directly affect signal propagation delays through interconnects, and thereby the performance of a circuit. Device variations are attributed to variations in gate length Lgate , gate width Wgate , and gate oxide thickness tox . Additional sources of variation include those in the drain and source active areas as well as variations in the doping concentration during fabrication. These variations affect the device properties, and thereby, affect circuit performance. The most important sources of device variation are Lgate, tox, and Vt threshold voltage . Since the ratio of Wgate Lgate determines the drain current of a CMOS transistor, if Wgate is much larger than Lgate, variation in Wgate is usually not considered [23]. We next try to qualitatively understand the impact of these variations on latency and power. It is intuitive that the variations in interconnect and device feature sizes contribute to uncertainty in their delays, and therefore, uncertainty in path delays of a circuit. We consider some critical path in a circuit, with the mean of its delay distributions being equal to the required value. The probability that this path satisfies the timing constraint is naturally 0.5 Parametric timing yield 50% . If we consider another independent critical path, the probability that the timing constraint of the circuit is met is reduced to 0.52 0.25 Parametric timing yield 25% . Although critical path delays are correlated in reality, this example gives an intuition of how the variations in device delays contribute to diminishing yields. To study the impact on parametric power yields that is, the probability of chips that satisfy the power consumption constraints , we separate total power into static and dynamic power. For dynamic power at a specified clock frequency, effective device and interconnect capacitance variations act as the primary source of variability. Next, the sub-threshold leakage is exponentially dependent on the threshold voltage Vt , which in turn strongly depends on the dopant concentration, and channel length Lgate [22]. Furthermore, the exponential dependence causes a large spread in the leakage power distribution. For large width transistors, the impact of doping variations on Vt is smaller in comparison to Lgate. While low Vt devices are commonly used in circuits to reduce latency, these devices are most vulnerable to high leakage power consumption, leading to large yield loss in high performance bins [6]. Statistical approaches, where the sources of variations are modeled as random variables with known distributions, are considered more suitable for process variation modeling. Analytical approaches to statistical timing analysis have been proposed recently [8, 38], but suffer from inaccuracies due to a large number of assumptions. However, these approaches are efficient and find use in optimization [36]. For accurate analysis, Monte Carlo simulations are widely employed. In this technique, random samples of the random variables are taken in each simulation. The distribution of the final result could be timing or power is observed after a large number of Monte Carlo runs have been performed. The
local word line global word line
in a die. Therefore, we use a correlation factor, which is a number between 0 and 1. Once a set of process variation parameters are given, we use these parameters as the new mean and scale the range of process variations given in Table 1 by the correlation factor. As a result, higher correlation factors imply less correlation between two random variables. Note that this definition is opposite to that of the correlation coefficient, wherein a higher correlation coefficient implies more correlation between two random variables. The correlation factors are calculated from the vertical and horizontal spatial correlation dependences presented by Friedberg et al. [15]. For each bit in a cache block, we have used a correlation factor of 0.01 and the correlation factor between rows is set to 0.05. Assuming that the ways are laid out on a 2 by 2 mesh, the way that is on the same vertical line with the first way uses the correlation factor 0.45 the way that is on the same horizontal line with the first way uses a the correlation factor 0.375. Finally, the way that is on the same diagonal line with the initial way uses the correlation factor 0.7125.
Table 1. Nominal and 3σ variation values for each source of process variations modeled
Nominal 45 220 0.25 0.55 0.15 Value nm mV μm μm μm 3σ var. [%] ±10 ±18 ±33 ±33 ±35
4. Yield-Aware Cache Architectures
In this section, we describe our architectural techniques to improve yield. There are two important factors that limit the yield excessive leakage and excessive delay. To address these two factors, we have developed two types of novel schemes, which are explained in the following sections. First, we discuss a power-down technique that minimizes the leakage consumption and hence increases yield. Then, in Section 4.2, we describe how the naïve power-down technique can be modified to increase the yield even further. This scheme is called the Horizontal Yield-Aware Power-Down H-YAPD . Section 4.3 discusses a variable access latency cache that aims to minimize yield losses due to delay constrains. In Section 4.4, we describe a hybrid scheme that employs both techniques to boost the yield even further.
4.1. Yield-Aware Power-Down YAPD
The Yield-Aware Power-Down YAPD technique is based on the Selective Cache Ways SCW method [4] combined with the Gated-Vdd technique [30]. Although SCW is implemented for reducing power, we use a similar method for improving yield. Particularly, the YAPD technique disables cache ways based on their delay and power consumptions. If a cache way violates maximum allowed latency constraint, it is turned off. Similarly, if the total power consumption of the cache exceeds the limit, the
decoder decoder
4.2. Horizontal YAPD H-YAPD
most or middle of the cache that causes the problem. Clearly, this scenario requires all the cache ways to experience the same or at least similar process variation parameters. Such a behavior is expected, because there is strong spatial correlation the variation parameters changes slightly from one way to another c.f., Sections 2 and 3 . One important issue with designing such a cache is that all the sets corresponding to the same address should not be turned off at the same time. To support correct operation, we need to change the decoder structures in each way. Figure 5 shows how we can modify the decoders for each way and which lines are enabled disabled by each cache way select signal. In this new configuration, all the blocks in a horizontal region corresponds to different addresses. As a result, if we turn a horizontal way off, each address will still have three possible positions. Consider the case where we turn off h-way 0. In that case, a block that is mapped between lines 0 and 31 can reside in vertical ways 1, 2, or 3. Similarly, an address that is mapped to block address 96 through 127 may reside in vertical ways 0, 2, and 3. In every case, we will search the blocks in exactly three locations. As a result, the hit miss behavior of this architecture will be identical to that of a 3-way cache, i.e., H-YAPD and YAPD will exhibit identical hit miss behavior. Such a decoder has no area or latency overhead compared to a regular decoder. We only change the configurations of the post-decoders. Figure 6 shows a cache architecture that implements H-YAPD for a 4-way cache where each way has 16 lines. One disadvantage of the H-YAPD is its increased latency. Since the granularity of the power-down is changed, we see an increase in the average latency of cache accesses. Simulations on the HSPICE model show a 2.5% increase in the access latencies on average. In addition, since some parts of the decoder as well as pre-charge and sense amplifier circuits cannot be turned off completely, the power savings may be lower than the YAPD.
One problem with the YAPD scheme is the correlation of process variation parameters between different cache ways. Particularly, since different banks ways of a cache are implemented physically close to each other, they are strongly correlated. As a result, if one way fails due to delay variation and or excessive leakage, the remaining ways also fail with high probability. It should be apparent that YAPD scheme described in the previous section would try to close most or all ways. To resolve this limitation, we develop a second yield-aware power-down scheme that disables a subset of rows in all ways. In other words, we effectively turn off a horizontal way, instead of a regular vertical way. The reasoning behind this scheme lies in the observation that different paths in a cache show a similar reaction to the same process variation parameters. To understand this behavior, assume that all the cache ways observe the same process variations. Also, assume that the upper-most row in the bank is the critical path, and a second near-critical path is in the middle of the same bank. For a particular set of process variation parameters, the latency of upper-most rows may increase 10%, while the latency of the middle rows will increase by 5%. In another variation, the latency of the middle rows will increase by 10%, while the latency of the upper-most rows will increase by 5%. As a result, for a given process variation, either all the upper-most rows of the ways or all the middle rows will violate the delay constraint. YAPD will then try to turn off all the ways. H-YAPD, on the other hand, will only turn off the sections e.g., upper-
decoder
4.3. Variable-Latency Cache Architecture
the destination register number and the data read from the cache are forwarded to the load-bypass buffers where each entry compares the stored register number which is the input register for the dependent instruction with the forwarded value. If the two values are identical, the data i.e., the output of the load operation is latched into the buffer. Then, in the next cycle the operation will start execution. Figure 7 shows the hardware for this approach. Note that we omitted the multiplexers at the inputs of the functional unit that selects from different forward values. If the input operands of an instruction are ready, i.e., no forwarding is needed from the cache the operation can simply skip the buffer and start the execution. However, if one of the input operands will be provided by a delayed load operation, the instruction will enter the buffer. Once it receives the data, it will move to the function unit as described above. If there is another instruction depending on this stalled operation, it also has to be stalled. This chain may continue for more operations depending on the latency of operations and the number of pipeline stages between scheduling and execution. To illustrate this, consider the instructions L1, D1, D2, …, Dn, where D1 is dependent on L1 and D2 is dependent on D1, etc. Once the load is delayed, D1 is stalled for a cycle in a load-bypass buffer. At the same time, the scheduler is informed about this stall hence the scheduling of any direct or indirect dependent instructions are delayed for one cycle. However, depending on the time between scheduling decision and the start of the execution, several operations may already been scheduled to execute. These operations will have to use the load-bypass buffers to stall for an additional cycle. In such cases, these dependent operations will receive their data from a function unit rather than the data cache. Therefore, the load-bypass buffers have to be connected to not only the data cache, but also to all the function units. If an instruction is in the load-bypass buffer but does not receive its input, it means that the load access missed in the cache. Therefore, the dependent instruction needs to be flushed and re-executed based on the replay mechanism that is employed in the processor. Note that the complexity of replay and the miss penalty of the load operations are not affected by our variable latency architecture.
Pipeline Register
To implement VACA, the scheduler in the processor has to be modified. Each instruction that is dependent on a load
4.4. Hybrid Scheme
4.5. Naïve Alternatives
To analyze the effectiveness of the proposed schemes, we need to analyze two different aspects their impact on the yield and their impact on performance. In the next section, we first describe the results analyzing their impact on yield. Section 5.2 discusses the performance implications. We must
note that the proposed schemes are only activated when a chip does not meet design criteria, i.e., when a chip would otherwise be discarded due to parametric yield loss. Therefore, the schemes do not have any performance impact on the rest of the chips that pass the testing.
5.1. Yield Results
In the core of the analysis lies our capability to estimate yield loss of a particular design. Therefore, we first present the methodology used to estimate yield loss. Similar to the methodology by Rao et al. [32], we first model 2000 different caches under process variations. To achieve this, we perform HSPICE simulations for 2000 caches, where each simulation picks a different set of process variation parameters from their respective intervals discussed in Section 3. Note that as we have described in Section 3, each simulation models 4 different cache ways by considering different critical near-critical paths for that particular way. After each simulation, we compare the address-to-data output latency of each path in a way and the maximum of these numbers gives the access latency for that cache way. Similarly, the maximum among all way latencies becomes the cache access latency. Using the same simulations, we also find the total leakage power consumption of each cache by summing over the leakage power consumed by each way. Figure 8 shows the distribution of normalized leakage power consumption versus distribution of cache access latencies. Once the latency versus leakage distribution is found, the yield can be calculated by setting power and performance limits. Rao et al. [32] analyze an ALU and use mean+sigma value for performance limit and 1.75xaverage leakage power limit for a 65 nm technology. Similar to their approach, we use the same performance limit. However, we picked the power limit at 3 times the average leakage power to compensate for the increased variation in 45 nm and the different component we are studying cache instead of ALU . Table 2 tabulates the distribution of the sources of parametric yield loss encountered in the base case and when we implement the YAPD, VACA, and Hybrid schemes. The total number of chips is 2000. Hence, with this architecture, the expected parametric yield loss is 16.9%. Similarly, Table 3 shows the results when we implement H-YAPD. As highlighted in Section 4.2, the cache architecture used in the H-YAPD scheme is slightly different than the YAPD architecture. Therefore, we have performed a different set of HSPICE simulations for 2000 caches representing the new architecture. We have applied the same process variation parameters used in the previous simulations. On average, we see that the delay of the architecture increases by 2.5%. As a
Circuit 5
4
Delay Constraint 36 36 20 7 2 Ways
# Losses with Scheme Reason of Loss Chips H-YAPD VACA Hybrid
Leakage Constraint 138 26 138 26
Delay Constraint 142 0 38 0
1 Way
Delay Constraint 33 33 17 6 2 Ways
Delay Constraint 29 24 21 12
3 Ways
Delay Constraint 20 17 19 16 4 Ways
result, the number of chips that do not meet the delay constraint increases. Particularly, for the base case of this cache architecture, we see that 18.1% of the chips are lost. We observe that YAPD and H-YAPD schemes decrease the parametric yield loss by 68.1% and 72.4%, respectively. Considering the overall yield, YAPD and H-YAPD increases the total yield to 94.6% and 95.0%, respectively. YAPD and H-YAPD reduces the losses due to leakage by 76.1% and 81.2%, respectively. They also nullify the losses due to a single way delay violations. VACA has a lower decrease in yield loss. As discussed in Section 4.3, all the chips with 6 or more cycles of cache access latency are considered as yield loss with VACA. Furthermore, VACA does not improve yield losses due to leakage. Overall, VACA reduces the yield loss by 33.3% for regular power-down and 35.6% for horizontal power-down caches. As expected, the Hybrid scheme performs the best in terms of yield improvement. Combining the benefits of both schemes, the Hybrid scheme reduces the losses due to leakage, eliminates all single way delay violation losses, and achieves further reduction in losses for multiple-way delay violations. The Hybrid scheme results in 81.1% and 83.4% reduction in parametric yield loss, for regular and horizontal power-down caches, respectively. Using the Hybrid scheme, the yield improves to 96.8% and 97.0% for the regular and horizontal power-down caches, respectively. An important aspect of yield loss modeling is the ability to change the constraints. Depending on the architecture, manufacturers can change the constraints on their chips. This also could be modeled with our approach. Therefore, we analyzed the advantages of our schemes while changing the
5.2. Performance Implications
Table 6. Performance degradation of SPEC2000 applications for different cache configurations using the YAPD, VACA, and Hybrid schemes.
2 2 0 16 N A 3.32 3.32 1 3 0 4 N A 5.47 5.47 0 4 0 1 N A 6.42 6.42 3 0 1 35 1.08 N A 1.08 2 1 1 13 N A N A 3.65 1 2 1 8 N A N A 5.49 0 3 1 2 N A N A 7.39 4 0 0 105 1.08 N A 1.08
Weighted 1.08 2.20 1.83
Sum
forwarding application-specific number of instructions as proposed by Sherwood et al. [34]. The base processor is a 4-way processor with an issue queue of 128 entries and a ROB of 256 entries. The simulated processor has separate level 1 instruction and data caches level 1 instruction cache is 16 KB, 4-way associative with 64-byte block size and 2 cycle latency, and the level 1 data cache is a 16 KB, 4-way associative with 32-byte block size and 4 cycle latency. Unified level 2 cache is 512 KB, 8-way associative cache with 128-byte block size and 25 cycle latency. The memory access delay is set to 350 cycles. All caches are lock-up free. The simulated architecture implements 7 pipeline stages between the schedule and execute stages. Table 6 lists the different cache way latency configurations encountered during HSPICE simulations that are converted from yield loss to yield gain along with the number of times they are encountered. In addition, it lists the average performance degradation for SPEC2000 applications caused by each of the schemes for a given configuration. The configuration 3-1-0 corresponds to the case where three out of four ways in a cache has 4-cycle access latency, whereas the fourth way requires an additional access cycle for correct operation. A configuration 3-0-1, on the other hand, corresponds to a cache with three ways requiring 4 cycles and another one requiring 6 or more
cycles. Note that the performance degradations of the YAPD and H-YAPD schemes are identical for a given cache
configuration. If multiple ways require 5 or more cycles, the chip is lost with the YAPD schemes. Similarly, the number of ways requiring 6 or more cycles of access should be equal to zero for VACA and at most one for Hybrid schemes. The last configuration, 4-0-0 shows the leakage power limited caches that did not violate the timing requirements. In this case, we need to shut down a way to reduce the leakage power consumption. Since VACA does not disable ways, it cannot save any cache with this configuration. The results presented in the bottom row of Table 6 correspond to a weighted sum of the performance degradation on the chips that are saved, i.e., the performance degradation for a configuration is multiplied by its fraction within the saved chips and summed over all configurations. To illustrate this, consider the sum for VACA. This number is achieved by first finding the total number of chips saved by it 112 . Then, the fraction of each saved configuration is found e.g., 91 112 0.81 for 3-1-0 . We multiply this fraction with the corresponding performance degradation e.g., 0.81*1.81% 1.46% and sum over all configurations 1.46%+0.47%+0.20%+0.06% 2.20% . This number corresponds to average performance degradation for the batch of chips that are saved. On average, for the saved chips, YAPD, VACA, and Hybrid schemes cause 1.1%, 2.2%, and 1.8% increase in the CPI, respectively. Figures 9 and 10 show the increase in CPI for different SPEC2000 applications for two frequent cache configurations listed above 3-1-0 and 2-2-0, respectively. In the case of 3-1-0, the hybrid scheme can either choose to close the 5-cycle latency way in this case like YAPD or keep
4,5 YAPD VACA
[%] 4
CPI 3
3,5
in 2,5
8
[%] 6
7 VACA
CPI 5
in 4
1
0
6. Related Work
variation effects due to smaller technologies, the number of candidate elements for sizing increases, complicating the application of such enhancements. Performance binning is another long-standing approach to increase yields [6, 10, 33]. Circuits are placed in separate bins depending on their performance and power consumption levels and marketed with different prices for each bin. As a result, lower performing bins can be sold at a lower price instead of merely getting thrown away. In this regard, Borkar et al. [6] combine the circuit level approaches with frequency binning. They propose a number of circuit level techniques to control body bias voltage, supply voltage, and temperature to get higher frequency bins. There are a number of architectural and system level approaches that can impact yield. Datta et al. [11] employs gate sizing to optimize individual stages in the processor pipeline optimizing yield for a given area constraint or minimizing area for a given yield constraint using the concept of area borrowing. Kurdahi et al. [21] demonstrates analysis techniques to model and improve the yield of SRAMs at the system level by proper accounting for the coupling between the algorithms targeted for an SoC and the performance, power, and yield of SRAMs used in implementing them. These studies attack the yield loss problem at a lower level compared to our methods. Agarwal et al. [3], on the other hand, propose a new cache design where individual cache lines can be turned off if they are found to be faulty. This approach resembles our yield-aware power-down schemes. However, their work concentrates on direct mapped caches. Also, their fine-grained approach neglects the spatial correlation among different circuit elements, making decoder and the cache controller unnecessarily complicated. Another work by Datta et al. [12] tries to predict the yield of a pipelined circuit with analytical models. They observe that introducing imbalances among paths in a pipeline stage actually increases the yield of the design. Finally, several approaches, such as Razor by Ernst et al. [14], can be applied to improve yield. However, to the best of our knowledge, the yield impact of such schemes has not been studied.
7. Conclusions
Reducing chip yields due to process variations is an important problem for circuit designers as well as manufacturers. In this work, we propose four microarchitectural techniques to minimize the yield loss due to power and delay violations in the data cache. We first discuss the major sources of process variations and model them using HSPICE. Then, we introduce our schemes. The first scheme, Yield-Aware Power-Down YAPD , disables a cache way if it violates the delay or power limits. The second scheme, Horizontal-YAPD H-YAPD , modifies the approach by turning off horizontal regions of a cache instead of the regular vertical ways. Due to spatial correlation of process variations, turning off segments that exhibit similar behavior improves the yield further. The third scheme, VAriable-latency Cache Architecture VACA , allows
References
D 9494
CA.
Figure 1. Yield factors for different process technologies [18]
Figure 2. Cross-section of parallel interconnect lines above a ground plane a the ideal case, b different types of variations that can exist in the interconnect
Figure 3. One cache way within the 16 KB, 4 way cache model
Figure 4. YAPD implementation on a 4-way cache
Figure 5. The high-level view of the decoders in the H-YAPD implementation
Figure 6. H-YAPD implementation on a 4-way cache
Figure 7. Implementation of the load-bypass buffer and the associated forwarding from the data cache
Figure 9.Increase in CPI for YAPD and VACA for cache configuration 3-1-0
Figure 10.Increase in CPI for VACA for cache configuration 2-2-0
